{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image, ImageFile\n",
    "from urllib2 import urlopen\n",
    "from django.core.validators import URLValidator\n",
    "from django.core.exceptions import ValidationError\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "def delete_model(model, clear_session=True):\n",
    "    '''removes model!\n",
    "    '''\n",
    "    del model\n",
    "    gc.collect()\n",
    "    if clear_session: K.clear_session()\n",
    "\n",
    "\n",
    "def is_url(url):\n",
    "    val = URLValidator()\n",
    "    try:\n",
    "        val(url)\n",
    "        return True\n",
    "    except ValidationError as e:\n",
    "        return False\n",
    "    \n",
    "def plot_channels(img):\n",
    "    _ , ax = plt.subplots(1, 3, sharex='col', sharey='row', figsize=(24, 6))\n",
    "    plt.suptitle('RBG Channels of an Image', size=20)\n",
    "    \n",
    "    np_img_r = np_img.copy()\n",
    "    np_img_r[:, :, 1] = np.zeros(shape=[img_height, img_width])\n",
    "    np_img_r[:, :, 2] = np.zeros(shape=[img_height, img_width])\n",
    "    ax[0].imshow(np_img_r)\n",
    "    ax[0].axis('off')\n",
    "    \n",
    "    np_img_g = np_img.copy()\n",
    "    np_img_g[:, :, 0] = np.zeros(shape=[img_height, img_width])\n",
    "    np_img_g[:, :, 2] = np.zeros(shape=[img_height, img_width])\n",
    "    ax[1].imshow(np_img_g)\n",
    "    ax[1].axis('off')\n",
    "    \n",
    "    np_img_b = np_img.copy()\n",
    "    np_img_b[:, :, 0] = np.zeros(shape=[img_height, img_width])\n",
    "    np_img_b[:, :, 1] = np.zeros(shape=[img_height, img_width])\n",
    "    ax[2].imshow(np_img_b)\n",
    "    ax[2].axis('off')\n",
    "\n",
    "\n",
    "def read_img_url(url):\n",
    "    file = urlopen(url)\n",
    "\n",
    "    img = Image.open(file)\n",
    "    \n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    return img\n",
    "\n",
    "def read_img_file(f):\n",
    "    img = Image.open(f)\n",
    "    \n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    return img\n",
    "\n",
    "\n",
    "def read_img(f):\n",
    "    if is_url(f):\n",
    "        img = read_img_url(f)\n",
    "    else:\n",
    "        img = read_img_file(f)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def resize_img_to_array(img, img_shape=(244, 244)):\n",
    "    img_array = np.array(\n",
    "        img.resize(\n",
    "            img_shape, \n",
    "            Image.ANTIALIAS\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "def make_resnet_conv(input_shape):\n",
    "    '''\n",
    "    Creates a ResNet50 model trained on ImageNet.\n",
    "    It includes no final activation function,\n",
    "    so model returns conv. features.\n",
    "    \n",
    "    `input_shape` is a tuple of integers.\n",
    "    '''\n",
    "    model = ResNet50(input_shape=input_shape, \n",
    "                     weights='imagenet', \n",
    "                     include_top=False)\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False   \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Stock/Train Embeddings from File, Fit KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robelmengistu/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15695, 2053)\n"
     ]
    }
   ],
   "source": [
    "#TODO remove all afkikea \n",
    "meta_path = 'trial.csv'\n",
    "X = pd.read_csv(meta_path)\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.product_id = X.product_id.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4229, 2053)\n"
     ]
    }
   ],
   "source": [
    "X_train = X[~X['product_id'].str.contains('afrikrea')]\n",
    "X_train = X_train[~X_train['gender'].str.contains('others')]\n",
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4229, 2048)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_conv_2d = X_train[[_ for _ in X_train.columns if \"x_\" in _]].values.astype(np.float)\n",
    "X_train_conv_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4229\n"
     ]
    }
   ],
   "source": [
    "col_names = ['filename', \"gender\", \"category\", \"product_id\"]\n",
    "datadir = '/Users/robelmengistu/Documents/CS230_project/data/'\n",
    "X_train_urls = X_train[[_ for _ in X_train.columns if _ in col_names]].values\n",
    "\n",
    "train_urls = []\n",
    "for url_split in X_train_urls:\n",
    "    url_a = datadir + \"/\".join(url_split)\n",
    "    #print url_a\n",
    "    train_urls.append(url_a)\n",
    "print len(train_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=8, n_neighbors=30, p=2, radius=1.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training KNN on 100K images w/ 2K features takes about 2 minutes!\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "knn = NearestNeighbors(n_neighbors=30, n_jobs=8, algorithm='ball_tree')\n",
    "knn.fit(X_train_conv_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn.kneighbors([X, 8, return_distance=True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knn_train_2d_4229.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#serialize \n",
    "from sklearn.externals import joblib\n",
    "knn_file = 'knn_train_2d_4229.pkl'\n",
    "joblib.dump(knn, knn_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swatch Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44520\n"
     ]
    }
   ],
   "source": [
    "tri_url_map = pickle.load( open( \"url_pickle.p\", \"rb\" ) )\n",
    "print len(tri_url_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44520\n"
     ]
    }
   ],
   "source": [
    "# Read From File\n",
    "tri_feat_map = pickle.load( open( \"feats_pickle.p\", \"rb\" ) )\n",
    "print len(tri_feat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dif_2 (index):\n",
    "    anc, pos, neg = tri_feat_map[index][0], tri_feat_map[index][1], tri_feat_map[index][2]\n",
    "    pos_diff =   np.linalg.norm((anc) - (pos))**2\n",
    "    neg_diff =  np.linalg.norm ((anc) - (neg))**2\n",
    "    return neg_diff - pos_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "10000 8331\n",
      "20000 17892\n",
      "30000 26770\n",
      "40000 35130\n"
     ]
    }
   ],
   "source": [
    "diff = []\n",
    "off_diff = []\n",
    "off_train, off_val, off_test = 0,0,0 \n",
    "semi_hard_triplets = [] \n",
    "for key, value in tri_feat_map.iteritems():\n",
    "    if calc_dif_2(key) > 0: \n",
    "        semi_hard_triplets.append((value[0], value[1], value[2]))\n",
    "    if key % 10000 == 0: print key, len(semi_hard_triplets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38536\n",
      "3 2048\n"
     ]
    }
   ],
   "source": [
    "print len(semi_hard_triplets)\n",
    "print len(semi_hard_triplets[0]), len(semi_hard_triplets[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Images Embeddings and Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/robelmengistu/Documents/CS230_project/data/women/women-skirts/468149363/2AmsaAfricanPrintMidiSkirtwithSashYellowBlue.jpeg\n"
     ]
    }
   ],
   "source": [
    "print train_urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4229, 2048) 4229\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = X_train_conv_2d\n",
    "stock_urls = train_urls\n",
    "print train_embeddings.shape, len(stock_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_n_set():\n",
    "    n_set = []\n",
    "    for train_data in train_embeddings: \n",
    "        n_set.append(knn.kneighbors(train_data.reshape(1, train_data.shape[0]), return_distance=True))\n",
    "        if len(n_set) % 500 == 0:\n",
    "            print len(n_set)\n",
    "    return n_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "stock_n_test = get_stock_n_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "total stock triplets:  96100\n"
     ]
    }
   ],
   "source": [
    "stock_triplets = []\n",
    "for i in range(len(stock_urls)):\n",
    "    neg_paths, pos_paths = get_triplets (stock_urls[i], stock_n_test[i], num_rec=30)\n",
    "    generate_triplets(stock_urls[i], neg_paths, pos_paths, stock_triplets)\n",
    "    if i % 1000 == 0: print i\n",
    "print \"total stock triplets: \", len(stock_triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Street Images Embeddings and Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11194 <type 'collections.defaultdict'>\n"
     ]
    }
   ],
   "source": [
    "test_eb = pickle.load(open( \"test_embeddings_11194.p\", \"rb\" ))\n",
    "print len(test_eb), type(test_eb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_urls = []\n",
    "street_test_urls = [] \n",
    "street_2d_feat = []\n",
    "street_test_2d_feat = []\n",
    "i = 0 \n",
    "\n",
    "for key,value in test_eb.iteritems():\n",
    "    i += 1\n",
    "    if i % 11 == 0: \n",
    "        street_test_urls.append(key)\n",
    "        street_test_2d_feat.append(value)\n",
    "    else: \n",
    "        street_urls.append(key)\n",
    "        street_2d_feat.append(value)\n",
    "\n",
    "street_2d_feat = np.asarray(street_2d_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( street_test_urls, open( \"street_test_urls.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( street_test_urls, open( \"street_test_urls_p3.p\", \"wb\" ), protocol= pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_street_n_set():\n",
    "    n_set = []\n",
    "    \n",
    "    for train_data in street_2d_feat: \n",
    "        n_set.append(knn.kneighbors(train_data.reshape(1, train_data.shape[0]), return_distance=True))\n",
    "        if len(n_set) % 500 == 0:\n",
    "            print len(n_set)\n",
    "    return n_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "street_n_test = get_street_n_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_n_train = street_n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "total triplets:  198320\n"
     ]
    }
   ],
   "source": [
    "street_triplets = []\n",
    "for i in range(len(street_urls)):\n",
    "    neg_paths, pos_paths = get_triplets (street_urls[i], street_n_train[i], num_rec=30)\n",
    "    generate_triplets(street_urls[i], neg_paths, pos_paths, street_triplets, street=True)\n",
    "    if i % 1000 == 0: print i\n",
    "print \"total triplets: \", len(street_triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge All Triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Number of Triplets  = 332956 <br> \n",
    "Train/Val/Test = 319900/6528/6528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332956\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "final_triplets = street_triplets + stock_triplets + semi_hard_triplets\n",
    "print len(final_triplets)\n",
    "shuffle(final_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total/train/val/test:  1000 964 18 18\n",
      "total/train/val/test:  2000 1924 38 38\n",
      "total/train/val/test:  3000 2884 58 58\n",
      "total/train/val/test:  4000 3844 78 78\n",
      "total/train/val/test:  5000 4804 98 98\n",
      "total/train/val/test:  6000 5768 116 116\n",
      "total/train/val/test:  7000 6728 136 136\n",
      "total/train/val/test:  8000 7688 156 156\n",
      "total/train/val/test:  9000 8648 176 176\n",
      "total/train/val/test:  10000 9608 196 196\n",
      "total/train/val/test:  11000 10572 214 214\n",
      "total/train/val/test:  12000 11532 234 234\n",
      "total/train/val/test:  13000 12492 254 254\n",
      "total/train/val/test:  14000 13452 274 274\n",
      "total/train/val/test:  15000 14412 294 294\n",
      "total/train/val/test:  16000 15376 312 312\n",
      "total/train/val/test:  17000 16336 332 332\n",
      "total/train/val/test:  18000 17296 352 352\n",
      "total/train/val/test:  19000 18256 372 372\n",
      "total/train/val/test:  20000 19216 392 392\n",
      "total/train/val/test:  21000 20180 410 410\n",
      "total/train/val/test:  22000 21140 430 430\n",
      "total/train/val/test:  23000 22100 450 450\n",
      "total/train/val/test:  24000 23060 470 470\n",
      "total/train/val/test:  25000 24020 490 490\n",
      "total/train/val/test:  26000 24984 508 508\n",
      "total/train/val/test:  27000 25944 528 528\n",
      "total/train/val/test:  28000 26904 548 548\n",
      "total/train/val/test:  29000 27864 568 568\n",
      "total/train/val/test:  30000 28824 588 588\n",
      "total/train/val/test:  31000 29788 606 606\n",
      "total/train/val/test:  32000 30748 626 626\n",
      "total/train/val/test:  33000 31708 646 646\n",
      "total/train/val/test:  34000 32668 666 666\n",
      "total/train/val/test:  35000 33628 686 686\n",
      "total/train/val/test:  36000 34592 704 704\n",
      "total/train/val/test:  37000 35552 724 724\n",
      "total/train/val/test:  38000 36512 744 744\n",
      "total/train/val/test:  39000 37472 764 764\n",
      "total/train/val/test:  40000 38432 784 784\n",
      "total/train/val/test:  41000 39396 802 802\n",
      "total/train/val/test:  42000 40356 822 822\n",
      "total/train/val/test:  43000 41316 842 842\n",
      "total/train/val/test:  44000 42276 862 862\n",
      "total/train/val/test:  45000 43236 882 882\n",
      "total/train/val/test:  46000 44198 902 900\n",
      "total/train/val/test:  47000 45160 920 920\n",
      "total/train/val/test:  48000 46120 940 940\n",
      "total/train/val/test:  49000 47080 960 960\n",
      "total/train/val/test:  50000 48040 980 980\n",
      "total/train/val/test:  51000 49000 1000 1000\n",
      "total/train/val/test:  52000 49964 1018 1018\n",
      "total/train/val/test:  53000 50924 1038 1038\n",
      "total/train/val/test:  54000 51884 1058 1058\n",
      "total/train/val/test:  55000 52844 1078 1078\n",
      "total/train/val/test:  56000 53804 1098 1098\n",
      "total/train/val/test:  57000 54768 1116 1116\n",
      "total/train/val/test:  58000 55728 1136 1136\n",
      "total/train/val/test:  59000 56688 1156 1156\n",
      "total/train/val/test:  60000 57648 1176 1176\n",
      "total/train/val/test:  61000 58608 1196 1196\n",
      "total/train/val/test:  62000 59572 1214 1214\n",
      "total/train/val/test:  63000 60532 1234 1234\n",
      "total/train/val/test:  64000 61492 1254 1254\n",
      "total/train/val/test:  65000 62452 1274 1274\n",
      "total/train/val/test:  66000 63412 1294 1294\n",
      "total/train/val/test:  67000 64376 1312 1312\n",
      "total/train/val/test:  68000 65336 1332 1332\n",
      "total/train/val/test:  69000 66296 1352 1352\n",
      "total/train/val/test:  70000 67256 1372 1372\n",
      "total/train/val/test:  71000 68216 1392 1392\n",
      "total/train/val/test:  72000 69180 1410 1410\n",
      "total/train/val/test:  73000 70140 1430 1430\n",
      "total/train/val/test:  74000 71100 1450 1450\n",
      "total/train/val/test:  75000 72060 1470 1470\n",
      "total/train/val/test:  76000 73020 1490 1490\n",
      "total/train/val/test:  77000 73984 1508 1508\n",
      "total/train/val/test:  78000 74944 1528 1528\n",
      "total/train/val/test:  79000 75904 1548 1548\n",
      "total/train/val/test:  80000 76864 1568 1568\n",
      "total/train/val/test:  81000 77824 1588 1588\n",
      "total/train/val/test:  82000 78788 1606 1606\n",
      "total/train/val/test:  83000 79748 1626 1626\n",
      "total/train/val/test:  84000 80708 1646 1646\n",
      "total/train/val/test:  85000 81668 1666 1666\n",
      "total/train/val/test:  86000 82628 1686 1686\n",
      "total/train/val/test:  87000 83592 1704 1704\n",
      "total/train/val/test:  88000 84552 1724 1724\n",
      "total/train/val/test:  89000 85512 1744 1744\n",
      "total/train/val/test:  90000 86472 1764 1764\n",
      "total/train/val/test:  91000 87432 1784 1784\n",
      "total/train/val/test:  92000 88396 1802 1802\n",
      "total/train/val/test:  93000 89356 1822 1822\n",
      "total/train/val/test:  94000 90316 1842 1842\n",
      "total/train/val/test:  95000 91276 1862 1862\n",
      "total/train/val/test:  96000 92236 1882 1882\n",
      "total/train/val/test:  97000 93198 1902 1900\n",
      "total/train/val/test:  98000 94160 1920 1920\n",
      "total/train/val/test:  99000 95120 1940 1940\n",
      "total/train/val/test:  100000 96080 1960 1960\n",
      "total/train/val/test:  101000 97040 1980 1980\n",
      "total/train/val/test:  102000 98000 2000 2000\n",
      "total/train/val/test:  103000 98964 2018 2018\n",
      "total/train/val/test:  104000 99924 2038 2038\n",
      "total/train/val/test:  105000 100884 2058 2058\n",
      "total/train/val/test:  106000 101844 2078 2078\n",
      "total/train/val/test:  107000 102804 2098 2098\n",
      "total/train/val/test:  108000 103768 2116 2116\n",
      "total/train/val/test:  109000 104728 2136 2136\n",
      "total/train/val/test:  110000 105688 2156 2156\n",
      "total/train/val/test:  111000 106648 2176 2176\n",
      "total/train/val/test:  112000 107608 2196 2196\n",
      "total/train/val/test:  113000 108572 2214 2214\n",
      "total/train/val/test:  114000 109532 2234 2234\n",
      "total/train/val/test:  115000 110492 2254 2254\n",
      "total/train/val/test:  116000 111452 2274 2274\n",
      "total/train/val/test:  117000 112412 2294 2294\n",
      "total/train/val/test:  118000 113376 2312 2312\n",
      "total/train/val/test:  119000 114336 2332 2332\n",
      "total/train/val/test:  120000 115296 2352 2352\n",
      "total/train/val/test:  121000 116256 2372 2372\n",
      "total/train/val/test:  122000 117216 2392 2392\n",
      "total/train/val/test:  123000 118180 2410 2410\n",
      "total/train/val/test:  124000 119140 2430 2430\n",
      "total/train/val/test:  125000 120100 2450 2450\n",
      "total/train/val/test:  126000 121060 2470 2470\n",
      "total/train/val/test:  127000 122020 2490 2490\n",
      "total/train/val/test:  128000 122984 2508 2508\n",
      "total/train/val/test:  129000 123944 2528 2528\n",
      "total/train/val/test:  130000 124904 2548 2548\n",
      "total/train/val/test:  131000 125864 2568 2568\n",
      "total/train/val/test:  132000 126824 2588 2588\n",
      "total/train/val/test:  133000 127788 2606 2606\n",
      "total/train/val/test:  134000 128748 2626 2626\n",
      "total/train/val/test:  135000 129708 2646 2646\n",
      "total/train/val/test:  136000 130668 2666 2666\n",
      "total/train/val/test:  137000 131628 2686 2686\n",
      "total/train/val/test:  138000 132592 2704 2704\n",
      "total/train/val/test:  139000 133552 2724 2724\n",
      "total/train/val/test:  140000 134512 2744 2744\n",
      "total/train/val/test:  141000 135472 2764 2764\n",
      "total/train/val/test:  142000 136432 2784 2784\n",
      "total/train/val/test:  143000 137396 2802 2802\n",
      "total/train/val/test:  144000 138356 2822 2822\n",
      "total/train/val/test:  145000 139316 2842 2842\n",
      "total/train/val/test:  146000 140276 2862 2862\n",
      "total/train/val/test:  147000 141236 2882 2882\n",
      "total/train/val/test:  148000 142198 2902 2900\n",
      "total/train/val/test:  149000 143160 2920 2920\n",
      "total/train/val/test:  150000 144120 2940 2940\n",
      "total/train/val/test:  151000 145080 2960 2960\n",
      "total/train/val/test:  152000 146040 2980 2980\n",
      "total/train/val/test:  153000 147000 3000 3000\n",
      "total/train/val/test:  154000 147964 3018 3018\n",
      "total/train/val/test:  155000 148924 3038 3038\n",
      "total/train/val/test:  156000 149884 3058 3058\n",
      "total/train/val/test:  157000 150844 3078 3078\n",
      "total/train/val/test:  158000 151804 3098 3098\n",
      "total/train/val/test:  159000 152768 3116 3116\n",
      "total/train/val/test:  160000 153728 3136 3136\n",
      "total/train/val/test:  161000 154688 3156 3156\n",
      "total/train/val/test:  162000 155648 3176 3176\n",
      "total/train/val/test:  163000 156608 3196 3196\n",
      "total/train/val/test:  164000 157572 3214 3214\n",
      "total/train/val/test:  165000 158532 3234 3234\n",
      "total/train/val/test:  166000 159492 3254 3254\n",
      "total/train/val/test:  167000 160452 3274 3274\n",
      "total/train/val/test:  168000 161412 3294 3294\n",
      "total/train/val/test:  169000 162376 3312 3312\n",
      "total/train/val/test:  170000 163336 3332 3332\n",
      "total/train/val/test:  171000 164296 3352 3352\n",
      "total/train/val/test:  172000 165256 3372 3372\n",
      "total/train/val/test:  173000 166216 3392 3392\n",
      "total/train/val/test:  174000 167180 3410 3410\n",
      "total/train/val/test:  175000 168140 3430 3430\n",
      "total/train/val/test:  176000 169100 3450 3450\n",
      "total/train/val/test:  177000 170060 3470 3470\n",
      "total/train/val/test:  178000 171020 3490 3490\n",
      "total/train/val/test:  179000 171984 3508 3508\n",
      "total/train/val/test:  180000 172944 3528 3528\n",
      "total/train/val/test:  181000 173904 3548 3548\n",
      "total/train/val/test:  182000 174864 3568 3568\n",
      "total/train/val/test:  183000 175824 3588 3588\n",
      "total/train/val/test:  184000 176788 3606 3606\n",
      "total/train/val/test:  185000 177748 3626 3626\n",
      "total/train/val/test:  186000 178708 3646 3646\n",
      "total/train/val/test:  187000 179668 3666 3666\n",
      "total/train/val/test:  188000 180628 3686 3686\n",
      "total/train/val/test:  189000 181592 3704 3704\n",
      "total/train/val/test:  190000 182552 3724 3724\n",
      "total/train/val/test:  191000 183512 3744 3744\n",
      "total/train/val/test:  192000 184472 3764 3764\n",
      "total/train/val/test:  193000 185432 3784 3784\n",
      "total/train/val/test:  194000 186396 3802 3802\n",
      "total/train/val/test:  195000 187356 3822 3822\n",
      "total/train/val/test:  196000 188316 3842 3842\n",
      "total/train/val/test:  197000 189276 3862 3862\n",
      "total/train/val/test:  198000 190236 3882 3882\n",
      "total/train/val/test:  199000 191198 3902 3900\n",
      "total/train/val/test:  200000 192160 3920 3920\n",
      "total/train/val/test:  201000 193120 3940 3940\n",
      "total/train/val/test:  202000 194080 3960 3960\n",
      "total/train/val/test:  203000 195040 3980 3980\n",
      "total/train/val/test:  204000 196000 4000 4000\n",
      "total/train/val/test:  205000 196964 4018 4018\n",
      "total/train/val/test:  206000 197924 4038 4038\n",
      "total/train/val/test:  207000 198884 4058 4058\n",
      "total/train/val/test:  208000 199844 4078 4078\n",
      "total/train/val/test:  209000 200804 4098 4098\n",
      "total/train/val/test:  210000 201768 4116 4116\n",
      "total/train/val/test:  211000 202728 4136 4136\n",
      "total/train/val/test:  212000 203688 4156 4156\n",
      "total/train/val/test:  213000 204648 4176 4176\n",
      "total/train/val/test:  214000 205608 4196 4196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total/train/val/test:  215000 206572 4214 4214\n",
      "total/train/val/test:  216000 207532 4234 4234\n",
      "total/train/val/test:  217000 208492 4254 4254\n",
      "total/train/val/test:  218000 209452 4274 4274\n",
      "total/train/val/test:  219000 210412 4294 4294\n",
      "total/train/val/test:  220000 211376 4312 4312\n",
      "total/train/val/test:  221000 212336 4332 4332\n",
      "total/train/val/test:  222000 213296 4352 4352\n",
      "total/train/val/test:  223000 214256 4372 4372\n",
      "total/train/val/test:  224000 215216 4392 4392\n",
      "total/train/val/test:  225000 216180 4410 4410\n",
      "total/train/val/test:  226000 217140 4430 4430\n",
      "total/train/val/test:  227000 218100 4450 4450\n",
      "total/train/val/test:  228000 219060 4470 4470\n",
      "total/train/val/test:  229000 220020 4490 4490\n",
      "total/train/val/test:  230000 220984 4508 4508\n",
      "total/train/val/test:  231000 221944 4528 4528\n",
      "total/train/val/test:  232000 222904 4548 4548\n",
      "total/train/val/test:  233000 223864 4568 4568\n",
      "total/train/val/test:  234000 224824 4588 4588\n",
      "total/train/val/test:  235000 225788 4606 4606\n",
      "total/train/val/test:  236000 226748 4626 4626\n",
      "total/train/val/test:  237000 227708 4646 4646\n",
      "total/train/val/test:  238000 228668 4666 4666\n",
      "total/train/val/test:  239000 229628 4686 4686\n",
      "total/train/val/test:  240000 230592 4704 4704\n",
      "total/train/val/test:  241000 231552 4724 4724\n",
      "total/train/val/test:  242000 232512 4744 4744\n",
      "total/train/val/test:  243000 233472 4764 4764\n",
      "total/train/val/test:  244000 234432 4784 4784\n",
      "total/train/val/test:  245000 235396 4802 4802\n",
      "total/train/val/test:  246000 236356 4822 4822\n",
      "total/train/val/test:  247000 237316 4842 4842\n",
      "total/train/val/test:  248000 238276 4862 4862\n",
      "total/train/val/test:  249000 239236 4882 4882\n",
      "total/train/val/test:  250000 240198 4902 4900\n",
      "total/train/val/test:  251000 241160 4920 4920\n",
      "total/train/val/test:  252000 242120 4940 4940\n",
      "total/train/val/test:  253000 243080 4960 4960\n",
      "total/train/val/test:  254000 244040 4980 4980\n",
      "total/train/val/test:  255000 245000 5000 5000\n",
      "total/train/val/test:  256000 245964 5018 5018\n",
      "total/train/val/test:  257000 246924 5038 5038\n",
      "total/train/val/test:  258000 247884 5058 5058\n",
      "total/train/val/test:  259000 248844 5078 5078\n",
      "total/train/val/test:  260000 249804 5098 5098\n",
      "total/train/val/test:  261000 250768 5116 5116\n",
      "total/train/val/test:  262000 251728 5136 5136\n",
      "total/train/val/test:  263000 252688 5156 5156\n",
      "total/train/val/test:  264000 253648 5176 5176\n",
      "total/train/val/test:  265000 254608 5196 5196\n",
      "total/train/val/test:  266000 255572 5214 5214\n",
      "total/train/val/test:  267000 256532 5234 5234\n",
      "total/train/val/test:  268000 257492 5254 5254\n",
      "total/train/val/test:  269000 258452 5274 5274\n",
      "total/train/val/test:  270000 259412 5294 5294\n",
      "total/train/val/test:  271000 260376 5312 5312\n",
      "total/train/val/test:  272000 261336 5332 5332\n",
      "total/train/val/test:  273000 262296 5352 5352\n",
      "total/train/val/test:  274000 263256 5372 5372\n",
      "total/train/val/test:  275000 264216 5392 5392\n",
      "total/train/val/test:  276000 265180 5410 5410\n",
      "total/train/val/test:  277000 266140 5430 5430\n",
      "total/train/val/test:  278000 267100 5450 5450\n",
      "total/train/val/test:  279000 268060 5470 5470\n",
      "total/train/val/test:  280000 269020 5490 5490\n",
      "total/train/val/test:  281000 269984 5508 5508\n",
      "total/train/val/test:  282000 270944 5528 5528\n",
      "total/train/val/test:  283000 271904 5548 5548\n",
      "total/train/val/test:  284000 272864 5568 5568\n",
      "total/train/val/test:  285000 273824 5588 5588\n",
      "total/train/val/test:  286000 274788 5606 5606\n",
      "total/train/val/test:  287000 275748 5626 5626\n",
      "total/train/val/test:  288000 276708 5646 5646\n",
      "total/train/val/test:  289000 277668 5666 5666\n",
      "total/train/val/test:  290000 278628 5686 5686\n",
      "total/train/val/test:  291000 279592 5704 5704\n",
      "total/train/val/test:  292000 280552 5724 5724\n",
      "total/train/val/test:  293000 281512 5744 5744\n",
      "total/train/val/test:  294000 282472 5764 5764\n",
      "total/train/val/test:  295000 283432 5784 5784\n",
      "total/train/val/test:  296000 284396 5802 5802\n",
      "total/train/val/test:  297000 285356 5822 5822\n",
      "total/train/val/test:  298000 286316 5842 5842\n",
      "total/train/val/test:  299000 287276 5862 5862\n",
      "total/train/val/test:  300000 288236 5882 5882\n",
      "total/train/val/test:  301000 289198 5902 5900\n",
      "total/train/val/test:  302000 290160 5920 5920\n",
      "total/train/val/test:  303000 291120 5940 5940\n",
      "total/train/val/test:  304000 292080 5960 5960\n",
      "total/train/val/test:  305000 293040 5980 5980\n",
      "total/train/val/test:  306000 294000 6000 6000\n",
      "total/train/val/test:  307000 294964 6018 6018\n",
      "total/train/val/test:  308000 295924 6038 6038\n",
      "total/train/val/test:  309000 296884 6058 6058\n",
      "total/train/val/test:  310000 297844 6078 6078\n",
      "total/train/val/test:  311000 298804 6098 6098\n",
      "total/train/val/test:  312000 299768 6116 6116\n",
      "total/train/val/test:  313000 300728 6136 6136\n",
      "total/train/val/test:  314000 301688 6156 6156\n",
      "total/train/val/test:  315000 302648 6176 6176\n",
      "total/train/val/test:  316000 303608 6196 6196\n",
      "total/train/val/test:  317000 304572 6214 6214\n",
      "total/train/val/test:  318000 305532 6234 6234\n",
      "total/train/val/test:  319000 306492 6254 6254\n",
      "total/train/val/test:  320000 307452 6274 6274\n",
      "total/train/val/test:  321000 308412 6294 6294\n",
      "total/train/val/test:  322000 309376 6312 6312\n",
      "total/train/val/test:  323000 310336 6332 6332\n",
      "total/train/val/test:  324000 311296 6352 6352\n",
      "total/train/val/test:  325000 312256 6372 6372\n",
      "total/train/val/test:  326000 313216 6392 6392\n",
      "total/train/val/test:  327000 314180 6410 6410\n",
      "total/train/val/test:  328000 315140 6430 6430\n",
      "total/train/val/test:  329000 316100 6450 6450\n",
      "total/train/val/test:  330000 317060 6470 6470\n",
      "total/train/val/test:  331000 318020 6490 6490\n",
      "total/train/val/test:  332000 318984 6508 6508\n"
     ]
    }
   ],
   "source": [
    "# total, train/val/test:  319900 6528 6528\n",
    "from collections import defaultdict \n",
    "triplet_count = 0\n",
    "train_count, val_count, test_count = 0,0,0\n",
    "t_set = \"train\"\n",
    "PRODUCT_INDEX = 6\n",
    "val_set_count, test_set_count = 0,0\n",
    "\n",
    "s_h_map = defaultdict(list)\n",
    "\n",
    "for tri_tuple in final_triplets:\n",
    "    if train_count >0 and  train_count% 98 == 0:\n",
    "        t_set = \"val\"\n",
    "        if val_set_count == 2:\n",
    "            t_set = \"test\"\n",
    "            if test_set_count == 2:\n",
    "                t_set = \"train\"\n",
    "    \n",
    "    s_h_map[t_set + \"a_file.pkl\"].append(tri_tuple[0])\n",
    "    s_h_map[t_set + \"p_file.pkl\"].append(tri_tuple[1])\n",
    "    s_h_map[t_set + \"n_file.pkl\"].append(tri_tuple[2])\n",
    "\n",
    "    \n",
    "    if t_set == \"train\": \n",
    "        train_count += 1 \n",
    "        val_set_count =0 \n",
    "        test_set_count = 0\n",
    "    elif t_set == \"val\": \n",
    "        test_set_count = 0\n",
    "        val_set_count += 1\n",
    "        val_count += 1 \n",
    "    elif t_set == \"test\": \n",
    "        test_count += 1 \n",
    "        test_set_count += 1\n",
    "    \n",
    "    triplet_count += 1\n",
    "\n",
    "    if triplet_count % 1000 == 0:\n",
    "        print \"total/train/val/test: \", triplet_count, train_count, val_count, test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total/train/val/test:  332956 319900 6528 6528\n"
     ]
    }
   ],
   "source": [
    "print \"total/train/val/test: \", triplet_count, train_count, val_count, test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319900\n"
     ]
    }
   ],
   "source": [
    "print len(s_h_map[\"train\"+\"p_file.pkl\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save All Embeddings to File "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Input for Triplet Network</b> <br>\n",
    "General File Structure: <br>\n",
    "- embedding_data_final <br>\n",
    "    - Train \n",
    "        - Anchor\n",
    "            - a_file.pkl\n",
    "        - Positives \n",
    "            - p_file.pkl\n",
    "        - Negatives \n",
    "            - n_file.pkl\n",
    "    - Test\n",
    "        ...\n",
    "    - Val \n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for t_set in [\"train\",\"val\", \"test\"]: \n",
    "    if not os.path.exists(\"embedding_data_final/\" + t_set+ \"/anchors/\" + \"/\"): \n",
    "        os.makedirs(\"embedding_data_final/\" + t_set+ \"/anchors/\")\n",
    "        path_a = \"embedding_data_final/\" + t_set+ \"/anchors/\" + \"a_file.pkl\"\n",
    "        pickle.dump(s_h_map[t_set+\"a_file.pkl\"] , open( path_a, \"wb\" ), protocol =pickle.HIGHEST_PROTOCOL )\n",
    "\n",
    "\n",
    "    if not os.path.exists(\"embedding_data_final/\" + t_set+ \"/negatives/\"  + \"/\"): \n",
    "        os.makedirs(\"embedding_data_final/\" + t_set+ \"/negatives/\")\n",
    "        path_n = \"embedding_data_final/\" + t_set+ \"/negatives\"  + \"/\" + \"n_file.pkl\"\n",
    "        pickle.dump(s_h_map[t_set+\"n_file.pkl\"] , open( path_n, \"wb\" ), protocol=pickle.HIGHEST_PROTOCOL )\n",
    "\n",
    "\n",
    "    if not os.path.exists(\"embedding_data_final/\" + t_set+\"/positives/\"  + \"/\"): \n",
    "        os.makedirs(\"embedding_data_final/\" + t_set+\"/positives/\")\n",
    "        path_p = \"embedding_data_final/\" + t_set+ \"/positives\"  + \"/\" + \"p_file.pkl\"\n",
    "        pickle.dump(s_h_map[t_set+\"p_file.pkl\"] , open( path_p, \"wb\" ), protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate hard triplets (Helper Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplets(url, neighbors, num_rec=8, per_row=4):\n",
    "    path_split = url.split(\"/\")\n",
    "    CATEGORY_INDEX = 7   #TODO: change depending on data location \n",
    "    PID_INDEX = 8\n",
    "    query_category = path_split[CATEGORY_INDEX]\n",
    "    distance = neighbors[0][0]\n",
    "    datadir = '/Users/robelmengistu/Documents/CS230_project/data/'\n",
    "    c = 0 \n",
    "    i = 0 \n",
    "    neg_count = 0 \n",
    "    neg_paths = []\n",
    "    pos_paths = []\n",
    "    while (True):\n",
    "        if c == num_rec: break \n",
    "        k = neighbors[1][0][i]\n",
    "        pd_id = train_urls[k].split(\"/\")[PID_INDEX]\n",
    "        pd_cat = train_urls[k].split(\"/\")[CATEGORY_INDEX] \n",
    "        \n",
    "        if pd_cat == query_category: pos_paths.append(train_urls[k])\n",
    "        else: neg_paths.append(train_urls[k])\n",
    "        i += 1\n",
    "        c += 1\n",
    "    return neg_paths[:5], pos_paths[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_triplets(anchor, neg_paths, pos_paths, triplets_list, street=False):\n",
    "    for neg in neg_paths:\n",
    "        for pos in pos_paths:\n",
    "            if street == True: \n",
    "                p_index, n_index = train_urls.index(pos), train_urls.index(neg)\n",
    "                triplets_list.append((test_eb[anchor],  train_embeddings[p_index], train_embeddings[n_index])) \n",
    "            else:\n",
    "                #print \"a,p,n: \", train_urls[train_urls.index(anchor)].split(\"/\")[7],  train_urls[train_urls.index(pos)].split(\"/\")[7],  train_urls[train_urls.index(neg)].split(\"/\")[7]\n",
    "                a_index, p_index, n_index = train_urls.index(anchor), train_urls.index(pos), train_urls.index(neg)\n",
    "                triplets_list.append((train_embeddings[a_index], train_embeddings[p_index], train_embeddings[n_index])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score (q_cat, r_cat, num_rec): \n",
    "\n",
    "    match_score =  1.0/num_rec\n",
    "    half_match_score = (1.0/(num_rec * 2))\n",
    "    \n",
    "    matching_sets = [[\"women-dresses\",\"women-outerwear\", \"women-matching-sets\"], [\"women-tops\", \"women-jackets\"]]\n",
    "    \n",
    "    half_match_set_1 = [\"women-jumpsuits\", \"women-pants-and-shorts\",\"women-matching-sets\",\"women-dresses\", \"women-skirts\"]\n",
    "    half_match_set_2 = [\"women-tops\", \"women-jackets\", \"women-dresses\", \"women-matching-sets\", \"women-outerwear\"]\n",
    "    \n",
    "    \n",
    "    match_tuples = []\n",
    "    for ms in matching_sets:\n",
    "        for i in ms:\n",
    "            for j in ms:\n",
    "                if i != j: match_tuples.append((i,j))\n",
    "    \n",
    "    half_match_tuples = []\n",
    "    for hs in [half_match_set_1, half_match_set_2]:\n",
    "        for i in hs:\n",
    "            for j in hs:\n",
    "                if i != j: half_match_tuples.append((i,j))\n",
    "    \n",
    "    \n",
    "    if r_cat == q_cat: return match_score\n",
    "    if (r_cat, q_cat) in match_tuples: return match_score\n",
    "    if (r_cat, q_cat) in half_match_tuples: return half_match_score\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc the mean avg. precision\n",
    "def get_map(url, neighbors, J, num_rec=8, per_row=4):\n",
    "    path_split = url.split(\"/\")\n",
    "    CATEGORY_INDEX = 7   #TODO: change depending on data location \n",
    "    query_category = path_split[7]\n",
    "    distance = neighbors[0][0]\n",
    "    datadir = '/Users/robelmengistu/Documents/CS230_project/data/'\n",
    "    c = 0 \n",
    "    i = 0 \n",
    "    MAP = 0 \n",
    "    accuracy = [] \n",
    "    product_recommended = []\n",
    "    while (True):\n",
    "        if c == num_rec: break \n",
    "        k = neighbors[1][0][i]\n",
    "        #print k, X_train['product_id'][k]\n",
    "        if J['product_id'][k] in product_recommended: \n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        accuracy.append(accuracy_score(query_category, J['category'][k], num_rec))\n",
    "        \n",
    "        MAP += (sum(accuracy)/len(accuracy))\n",
    "        \n",
    "        i += 1\n",
    "        c += 1\n",
    "        product_recommended.append(J['product_id'][k])\n",
    "    \n",
    "    \n",
    "    return MAP\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors_set(f_set, knn_file):\n",
    "    '''\n",
    "    Loads the KNN file, and a pre-trained neural network.\n",
    "    Converts image (f) to convoultional features,\n",
    "    Sends conv features to KNN to find closest hits,\n",
    "    Plots the top images and their distances.\n",
    "    '''\n",
    "    knn = joblib.load(knn_file) \n",
    "    model = make_resnet_conv(input_shape=[img_width, img_height, 3])\n",
    "    neighbors_set = []\n",
    "    for f in f_set: \n",
    "        X_conv_2d = get_conv_feats(f, model)\n",
    "        neighbors = knn.kneighbors(X_conv_2d, return_distance=True)\n",
    "        neighbors_set.append(neighbors)\n",
    "    delete_model(model)\n",
    "    return neighbors_set"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
